Dump of assembler code for function HarmonicSeriesAVX512:
harmonic_series.c:
92	double HarmonicSeriesAVX512(const unsigned long long int N) {
93	  struct timespec t[2];
94	  unsigned long long int i;
95	  __m512d sumv = _mm512_setzero_pd();
96	  __m512d onesv =_mm512_set1_pd(1.0);
97	  __m512d eightv =_mm512_set1_pd(8.0);
98	  __m512d divv = _mm512_set_pd(1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0);
99	
100	  clock_gettime(CLOCK_MONOTONIC, &t[0]);
   0x0000000000402950 <+0>:	4c 8d 54 24 08	lea    0x8(%rsp),%r10
   0x0000000000402955 <+5>:	48 83 e4 c0	and    $0xffffffffffffffc0,%rsp
   0x0000000000402959 <+9>:	41 ff 72 f8	push   -0x8(%r10)
   0x000000000040295d <+13>:	55	push   %rbp
   0x000000000040295e <+14>:	48 89 e5	mov    %rsp,%rbp
   0x0000000000402961 <+17>:	41 52	push   %r10
   0x0000000000402963 <+19>:	53	push   %rbx
   0x0000000000402964 <+20>:	48 8d 75 b0	lea    -0x50(%rbp),%rsi

92	double HarmonicSeriesAVX512(const unsigned long long int N) {
   0x0000000000402968 <+24>:	48 89 fb	mov    %rdi,%rbx

99	
100	  clock_gettime(CLOCK_MONOTONIC, &t[0]);
   0x000000000040296b <+27>:	bf 01 00 00 00	mov    $0x1,%edi

92	double HarmonicSeriesAVX512(const unsigned long long int N) {
   0x0000000000402970 <+32>:	48 81 ec a0 00 00 00	sub    $0xa0,%rsp

99	
100	  clock_gettime(CLOCK_MONOTONIC, &t[0]);
   0x0000000000402977 <+39>:	e8 e4 e6 ff ff	call   0x401060 <clock_gettime@plt>

101	  for(i=0; i<N; ++i) {
   0x000000000040297c <+44>:	48 85 db	test   %rbx,%rbx
   0x000000000040297f <+47>:	0f 84 0b 01 00 00	je     0x402a90 <HarmonicSeriesAVX512+320>

98	  __m512d divv = _mm512_set_pd(1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0);
   0x0000000000402985 <+53>:	62 f1 fd 48 28 05 b1 09 00 00	vmovapd 0x9b1(%rip),%zmm0        # 0x403340

95	  __m512d sumv = _mm512_setzero_pd();
   0x000000000040298f <+63>:	c5 f1 57 c9	vxorpd %xmm1,%xmm1,%xmm1

101	  for(i=0; i<N; ++i) {
   0x0000000000402993 <+67>:	31 c0	xor    %eax,%eax
   0x0000000000402995 <+69>:	62 f2 fd 48 19 25 d9 09 00 00	vbroadcastsd 0x9d9(%rip),%zmm4        # 0x403378
   0x000000000040299f <+79>:	62 f2 fd 48 19 1d 97 09 00 00	vbroadcastsd 0x997(%rip),%zmm3        # 0x403340
   0x00000000004029a9 <+89>:	0f 1f 80 00 00 00 00	nopl   0x0(%rax)

/usr/lib/gcc/x86_64-redhat-linux/12/include/avx512fintrin.h:
12570	  return (__m512d) ((__v8df)__A + (__v8df)__B);
   0x00000000004029b0 <+96>:	48 83 c0 01	add    $0x1,%rax

12571	}
12572	
12573	extern __inline __m512d
12574	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12575	_mm512_mask_add_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
12576	{
12577	  return (__m512d) __builtin_ia32_addpd512_mask ((__v8df) __A,
12578							 (__v8df) __B,
12579							 (__v8df) __W,
12580							 (__mmask8) __U,
12581							 _MM_FROUND_CUR_DIRECTION);
12582	}
12583	
12584	extern __inline __m512d
12585	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12586	_mm512_maskz_add_pd (__mmask8 __U, __m512d __A, __m512d __B)
12587	{
12588	  return (__m512d) __builtin_ia32_addpd512_mask ((__v8df) __A,
12589							 (__v8df) __B,
12590							 (__v8df)
12591							 _mm512_setzero_pd (),
12592							 (__mmask8) __U,
12593							 _MM_FROUND_CUR_DIRECTION);
12594	}
12595	
12596	extern __inline __m512
12597	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12598	_mm512_add_ps (__m512 __A, __m512 __B)
12599	{
12600	  return (__m512) ((__v16sf)__A + (__v16sf)__B);
12601	}
12602	
12603	extern __inline __m512
12604	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12605	_mm512_mask_add_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
12606	{
12607	  return (__m512) __builtin_ia32_addps512_mask ((__v16sf) __A,
12608							(__v16sf) __B,
12609							(__v16sf) __W,
12610							(__mmask16) __U,
12611							_MM_FROUND_CUR_DIRECTION);
12612	}
12613	
12614	extern __inline __m512
12615	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12616	_mm512_maskz_add_ps (__mmask16 __U, __m512 __A, __m512 __B)
12617	{
12618	  return (__m512) __builtin_ia32_addps512_mask ((__v16sf) __A,
12619							(__v16sf) __B,
12620							(__v16sf)
12621							_mm512_setzero_ps (),
12622							(__mmask16) __U,
12623							_MM_FROUND_CUR_DIRECTION);
12624	}
12625	
12626	extern __inline __m128d
12627	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12628	_mm_mask_add_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
12629	{
12630	  return (__m128d) __builtin_ia32_addsd_mask_round ((__v2df) __A,
12631							(__v2df) __B,
12632							(__v2df) __W,
12633							(__mmask8) __U,
12634							_MM_FROUND_CUR_DIRECTION);
12635	}
12636	
12637	extern __inline __m128d
12638	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12639	_mm_maskz_add_sd (__mmask8 __U, __m128d __A, __m128d __B)
12640	{
12641	  return (__m128d) __builtin_ia32_addsd_mask_round ((__v2df) __A,
12642							(__v2df) __B,
12643							(__v2df)
12644							_mm_setzero_pd (),
12645							(__mmask8) __U,
12646							_MM_FROUND_CUR_DIRECTION);
12647	}
12648	
12649	extern __inline __m128
12650	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12651	_mm_mask_add_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
12652	{
12653	  return (__m128) __builtin_ia32_addss_mask_round ((__v4sf) __A,
12654							(__v4sf) __B,
12655							(__v4sf) __W,
12656							(__mmask8) __U,
12657							_MM_FROUND_CUR_DIRECTION);
12658	}
12659	
12660	extern __inline __m128
12661	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12662	_mm_maskz_add_ss (__mmask8 __U, __m128 __A, __m128 __B)
12663	{
12664	  return (__m128) __builtin_ia32_addss_mask_round ((__v4sf) __A,
12665							(__v4sf) __B,
12666							(__v4sf)
12667							_mm_setzero_ps (),
12668							(__mmask8) __U,
12669							_MM_FROUND_CUR_DIRECTION);
12670	}
12671	
12672	extern __inline __m512d
12673	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12674	_mm512_sub_pd (__m512d __A, __m512d __B)
12675	{
12676	  return (__m512d) ((__v8df)__A - (__v8df)__B);
12677	}
12678	
12679	extern __inline __m512d
12680	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12681	_mm512_mask_sub_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
12682	{
12683	  return (__m512d) __builtin_ia32_subpd512_mask ((__v8df) __A,
12684							 (__v8df) __B,
12685							 (__v8df) __W,
12686							 (__mmask8) __U,
12687							 _MM_FROUND_CUR_DIRECTION);
12688	}
12689	
12690	extern __inline __m512d
12691	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12692	_mm512_maskz_sub_pd (__mmask8 __U, __m512d __A, __m512d __B)
12693	{
12694	  return (__m512d) __builtin_ia32_subpd512_mask ((__v8df) __A,
12695							 (__v8df) __B,
12696							 (__v8df)
12697							 _mm512_setzero_pd (),
12698							 (__mmask8) __U,
12699							 _MM_FROUND_CUR_DIRECTION);
12700	}
12701	
12702	extern __inline __m512
12703	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12704	_mm512_sub_ps (__m512 __A, __m512 __B)
12705	{
12706	  return (__m512) ((__v16sf)__A - (__v16sf)__B);
12707	}
12708	
12709	extern __inline __m512
12710	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12711	_mm512_mask_sub_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
12712	{
12713	  return (__m512) __builtin_ia32_subps512_mask ((__v16sf) __A,
12714							(__v16sf) __B,
12715							(__v16sf) __W,
12716							(__mmask16) __U,
12717							_MM_FROUND_CUR_DIRECTION);
12718	}
12719	
12720	extern __inline __m512
12721	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12722	_mm512_maskz_sub_ps (__mmask16 __U, __m512 __A, __m512 __B)
12723	{
12724	  return (__m512) __builtin_ia32_subps512_mask ((__v16sf) __A,
12725							(__v16sf) __B,
12726							(__v16sf)
12727							_mm512_setzero_ps (),
12728							(__mmask16) __U,
12729							_MM_FROUND_CUR_DIRECTION);
12730	}
12731	
12732	extern __inline __m128d
12733	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12734	_mm_mask_sub_sd (__m128d __W, __mmask8 __U, __m128d __A, __m128d __B)
12735	{
12736	  return (__m128d) __builtin_ia32_subsd_mask_round ((__v2df) __A,
12737							(__v2df) __B,
12738							(__v2df) __W,
12739							(__mmask8) __U,
12740							_MM_FROUND_CUR_DIRECTION);
12741	}
12742	
12743	extern __inline __m128d
12744	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12745	_mm_maskz_sub_sd (__mmask8 __U, __m128d __A, __m128d __B)
12746	{
12747	  return (__m128d) __builtin_ia32_subsd_mask_round ((__v2df) __A,
12748							(__v2df) __B,
12749							(__v2df)
12750							_mm_setzero_pd (),
12751							(__mmask8) __U,
12752							_MM_FROUND_CUR_DIRECTION);
12753	}
12754	
12755	extern __inline __m128
12756	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12757	_mm_mask_sub_ss (__m128 __W, __mmask8 __U, __m128 __A, __m128 __B)
12758	{
12759	  return (__m128) __builtin_ia32_subss_mask_round ((__v4sf) __A,
12760							(__v4sf) __B,
12761							(__v4sf) __W,
12762							(__mmask8) __U,
12763							_MM_FROUND_CUR_DIRECTION);
12764	}
12765	
12766	extern __inline __m128
12767	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12768	_mm_maskz_sub_ss (__mmask8 __U, __m128 __A, __m128 __B)
12769	{
12770	  return (__m128) __builtin_ia32_subss_mask_round ((__v4sf) __A,
12771							(__v4sf) __B,
12772							(__v4sf)
12773							_mm_setzero_ps (),
12774							(__mmask8) __U,
12775							_MM_FROUND_CUR_DIRECTION);
12776	}
12777	
12778	extern __inline __m512d
12779	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12780	_mm512_mul_pd (__m512d __A, __m512d __B)
12781	{
12782	  return (__m512d) ((__v8df)__A * (__v8df)__B);
12783	}
12784	
12785	extern __inline __m512d
12786	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12787	_mm512_mask_mul_pd (__m512d __W, __mmask8 __U, __m512d __A, __m512d __B)
12788	{
12789	  return (__m512d) __builtin_ia32_mulpd512_mask ((__v8df) __A,
12790							 (__v8df) __B,
12791							 (__v8df) __W,
12792							 (__mmask8) __U,
12793							 _MM_FROUND_CUR_DIRECTION);
12794	}
12795	
12796	extern __inline __m512d
12797	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12798	_mm512_maskz_mul_pd (__mmask8 __U, __m512d __A, __m512d __B)
12799	{
12800	  return (__m512d) __builtin_ia32_mulpd512_mask ((__v8df) __A,
12801							 (__v8df) __B,
12802							 (__v8df)
12803							 _mm512_setzero_pd (),
12804							 (__mmask8) __U,
12805							 _MM_FROUND_CUR_DIRECTION);
12806	}
12807	
12808	extern __inline __m512
12809	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12810	_mm512_mul_ps (__m512 __A, __m512 __B)
12811	{
12812	  return (__m512) ((__v16sf)__A * (__v16sf)__B);
12813	}
12814	
12815	extern __inline __m512
12816	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12817	_mm512_mask_mul_ps (__m512 __W, __mmask16 __U, __m512 __A, __m512 __B)
12818	{
12819	  return (__m512) __builtin_ia32_mulps512_mask ((__v16sf) __A,
12820							(__v16sf) __B,
12821							(__v16sf) __W,
12822							(__mmask16) __U,
12823							_MM_FROUND_CUR_DIRECTION);
12824	}
12825	
12826	extern __inline __m512
12827	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12828	_mm512_maskz_mul_ps (__mmask16 __U, __m512 __A, __m512 __B)
12829	{
12830	  return (__m512) __builtin_ia32_mulps512_mask ((__v16sf) __A,
12831							(__v16sf) __B,
12832							(__v16sf)
12833							_mm512_setzero_ps (),
12834							(__mmask16) __U,
12835							_MM_FROUND_CUR_DIRECTION);
12836	}
12837	
12838	extern __inline __m128d
12839	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12840	_mm_mask_mul_sd (__m128d __W, __mmask8 __U, __m128d __A,
12841				  __m128d __B)
12842	{
12843	  return (__m128d) __builtin_ia32_mulsd_mask_round ((__v2df) __A,
12844							 (__v2df) __B,
12845							 (__v2df) __W,
12846							 (__mmask8) __U,
12847							  _MM_FROUND_CUR_DIRECTION);
12848	}
12849	
12850	extern __inline __m128d
12851	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12852	_mm_maskz_mul_sd (__mmask8 __U, __m128d __A, __m128d __B)
12853	{
12854	  return (__m128d) __builtin_ia32_mulsd_mask_round ((__v2df) __A,
12855							 (__v2df) __B,
12856							 (__v2df)
12857							 _mm_setzero_pd (),
12858							 (__mmask8) __U,
12859							  _MM_FROUND_CUR_DIRECTION);
12860	}
12861	
12862	extern __inline __m128
12863	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12864	_mm_mask_mul_ss (__m128 __W, __mmask8 __U, __m128 __A,
12865				  __m128 __B)
12866	{
12867	  return (__m128) __builtin_ia32_mulss_mask_round ((__v4sf) __A,
12868							 (__v4sf) __B,
12869							 (__v4sf) __W,
12870							 (__mmask8) __U,
12871							  _MM_FROUND_CUR_DIRECTION);
12872	}
12873	
12874	extern __inline __m128
12875	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12876	_mm_maskz_mul_ss (__mmask8 __U, __m128 __A, __m128 __B)
12877	{
12878	  return (__m128) __builtin_ia32_mulss_mask_round ((__v4sf) __A,
12879							 (__v4sf) __B,
12880							 (__v4sf)
12881							 _mm_setzero_ps (),
12882							 (__mmask8) __U,
12883							  _MM_FROUND_CUR_DIRECTION);
12884	}
12885	
12886	extern __inline __m512d
12887	__attribute__ ((__gnu_inline__, __always_inline__, __artificial__))
12888	_mm512_div_pd (__m512d __M, __m512d __V)
12889	{
12890	  return (__m512d) ((__v8df)__M / (__v8df)__V);
   0x00000000004029b4 <+100>:	62 f1 dd 48 5e d0	vdivpd %zmm0,%zmm4,%zmm2

12570	  return (__m512d) ((__v8df)__A + (__v8df)__B);
   0x00000000004029ba <+106>:	62 f1 fd 48 58 c3	vaddpd %zmm3,%zmm0,%zmm0
   0x00000000004029c0 <+112>:	62 f1 f5 48 58 ca	vaddpd %zmm2,%zmm1,%zmm1

harmonic_series.c:
101	  for(i=0; i<N; ++i) {
   0x00000000004029c6 <+118>:	48 39 c3	cmp    %rax,%rbx
   0x00000000004029c9 <+121>:	75 e5	jne    0x4029b0 <HarmonicSeriesAVX512+96>
   0x00000000004029cb <+123>:	62 f1 fd 48 29 8d 50 ff ff ff	vmovapd %zmm1,-0xb0(%rbp)

102	    sumv = _mm512_add_pd( _mm512_div_pd(onesv, divv), sumv);
103	    divv = _mm512_add_pd(eightv, divv);
104	  }
105	  clock_gettime(CLOCK_MONOTONIC, &t[1]);
   0x00000000004029d5 <+133>:	48 8d 75 c0	lea    -0x40(%rbp),%rsi
   0x00000000004029d9 <+137>:	bf 01 00 00 00	mov    $0x1,%edi
   0x00000000004029de <+142>:	c5 f8 77	vzeroupper 
   0x00000000004029e1 <+145>:	e8 7a e6 ff ff	call   0x401060 <clock_gettime@plt>

51	  fprintf(stdout,"Time elapsed: %g s\n", run_time);
   0x00000000004029e6 <+150>:	c5 e8 57 d2	vxorps %xmm2,%xmm2,%xmm2
   0x00000000004029ea <+154>:	48 8b 3d 8f 26 00 00	mov    0x268f(%rip),%rdi        # 0x405080 <stdout@GLIBC_2.2.5>

49	    ( (double)(end->tv_nsec) - (double)(start->tv_nsec) ) / 1.0E9;
   0x00000000004029f1 <+161>:	c4 e1 eb 2a 5d b8	vcvtsi2sdq -0x48(%rbp),%xmm2,%xmm3

50	
51	  fprintf(stdout,"Time elapsed: %g s\n", run_time);
   0x00000000004029f7 <+167>:	be 10 30 40 00	mov    $0x403010,%esi
   0x00000000004029fc <+172>:	b8 01 00 00 00	mov    $0x1,%eax

49	    ( (double)(end->tv_nsec) - (double)(start->tv_nsec) ) / 1.0E9;
   0x0000000000402a01 <+177>:	c4 e1 eb 2a 45 c8	vcvtsi2sdq -0x38(%rbp),%xmm2,%xmm0
   0x0000000000402a07 <+183>:	c5 fb 5c c3	vsubsd %xmm3,%xmm0,%xmm0
   0x0000000000402a0b <+187>:	c5 fb 5e 05 2d 08 00 00	vdivsd 0x82d(%rip),%xmm0,%xmm0        # 0x403240

48	  double run_time = (double)(end->tv_sec) - (double)(start->tv_sec) +
   0x0000000000402a13 <+195>:	c4 e1 eb 2a 5d c0	vcvtsi2sdq -0x40(%rbp),%xmm2,%xmm3
   0x0000000000402a19 <+201>:	c4 e1 eb 2a 55 b0	vcvtsi2sdq -0x50(%rbp),%xmm2,%xmm2
   0x0000000000402a1f <+207>:	c5 e3 5c da	vsubsd %xmm2,%xmm3,%xmm3
   0x0000000000402a23 <+211>:	c5 fb 58 c3	vaddsd %xmm3,%xmm0,%xmm0

50	
51	  fprintf(stdout,"Time elapsed: %g s\n", run_time);
   0x0000000000402a27 <+215>:	e8 64 e6 ff ff	call   0x401090 <fprintf@plt>

106	  printTimer(&t[0], &t[1]);
107	
108	  double c[8];
109	  double sum = 0.0;;
110	  _mm512_storeu_pd(c, sumv); // write sumv to c array
111	  for (i=0; i<8; ++i) {
112	    //printf("%d %g\n", i, c[i]);
113	    sum += c[i];
   0x0000000000402a2c <+220>:	c5 d9 57 e4	vxorpd %xmm4,%xmm4,%xmm4
   0x0000000000402a30 <+224>:	62 f1 fd 48 28 8d 50 ff ff ff	vmovapd -0xb0(%rbp),%zmm1
   0x0000000000402a3a <+234>:	c5 f3 58 dc	vaddsd %xmm4,%xmm1,%xmm3
   0x0000000000402a3e <+238>:	c5 f1 15 d1	vunpckhpd %xmm1,%xmm1,%xmm2
   0x0000000000402a42 <+242>:	c4 e3 7d 19 c8 01	vextractf128 $0x1,%ymm1,%xmm0
   0x0000000000402a48 <+248>:	62 f3 fd 48 1b c9 01	vextractf64x4 $0x1,%zmm1,%ymm1
   0x0000000000402a4f <+255>:	c5 eb 58 d3	vaddsd %xmm3,%xmm2,%xmm2
   0x0000000000402a53 <+259>:	c5 eb 58 d0	vaddsd %xmm0,%xmm2,%xmm2
   0x0000000000402a57 <+263>:	c5 f9 15 c0	vunpckhpd %xmm0,%xmm0,%xmm0
   0x0000000000402a5b <+267>:	c5 fb 58 c2	vaddsd %xmm2,%xmm0,%xmm0
   0x0000000000402a5f <+271>:	c5 f1 15 d1	vunpckhpd %xmm1,%xmm1,%xmm2
   0x0000000000402a63 <+275>:	c5 fb 58 c1	vaddsd %xmm1,%xmm0,%xmm0
   0x0000000000402a67 <+279>:	c4 e3 7d 19 c9 01	vextractf128 $0x1,%ymm1,%xmm1
   0x0000000000402a6d <+285>:	c5 fb 58 c2	vaddsd %xmm2,%xmm0,%xmm0

114	  }
115	  return sum;
   0x0000000000402a71 <+289>:	c5 fb 58 c1	vaddsd %xmm1,%xmm0,%xmm0

113	    sum += c[i];
   0x0000000000402a75 <+293>:	c5 f1 15 c9	vunpckhpd %xmm1,%xmm1,%xmm1
   0x0000000000402a79 <+297>:	c5 fb 58 c1	vaddsd %xmm1,%xmm0,%xmm0
   0x0000000000402a7d <+301>:	c5 f8 77	vzeroupper 

116	}
   0x0000000000402a80 <+304>:	48 81 c4 a0 00 00 00	add    $0xa0,%rsp
   0x0000000000402a87 <+311>:	5b	pop    %rbx
   0x0000000000402a88 <+312>:	41 5a	pop    %r10
   0x0000000000402a8a <+314>:	5d	pop    %rbp
   0x0000000000402a8b <+315>:	49 8d 62 f8	lea    -0x8(%r10),%rsp
   0x0000000000402a8f <+319>:	c3	ret    

95	  __m512d sumv = _mm512_setzero_pd();
   0x0000000000402a90 <+320>:	c5 f1 57 c9	vxorpd %xmm1,%xmm1,%xmm1
   0x0000000000402a94 <+324>:	e9 32 ff ff ff	jmp    0x4029cb <HarmonicSeriesAVX512+123>
End of assembler dump.
